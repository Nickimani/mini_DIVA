{"cells":[{"cell_type":"markdown","metadata":{"id":"N24ZVYY38CPk"},"source":["# Loading data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\nick\\OneDrive\\Desktop\\Prospect 33\\Mini_DIVA\n"]}],"source":["%cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ebT9PW8dJlZI"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import StratifiedShuffleSplit\n","\n","pd.set_option('display.max_columns', None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2GtNGY0oJlZL"},"outputs":[],"source":["# the new data is in a folder called new_datasets\n","data_dir = \"../Mini_DIVA/new_datasets/\"\n","file_dir = data_dir + 'King_county.csv'\n","\n","# read the data\n","df = pd.read_csv(file_dir)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-VC6G8MJlZM","outputId":"b5495165-232d-4db2-ced8-877dc3d360ba"},"outputs":[{"name":"stdout","output_type":"stream","text":["(21613, 21)\n"]},{"data":{"text/plain":["id               0\n","date             0\n","price            0\n","bedrooms         0\n","bathrooms        0\n","sqft_living      0\n","sqft_lot         0\n","floors           0\n","waterfront       0\n","view             0\n","condition        0\n","grade            0\n","sqft_above       0\n","sqft_basement    0\n","yr_built         0\n","yr_renovated     0\n","zipcode          0\n","lat              0\n","long             0\n","sqft_living15    0\n","sqft_lot15       0\n","dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["print(df.shape)\n","display(df.isna().sum())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0KmFbf3sJlZM"},"outputs":[],"source":["# drop all nan values\n","df.dropna(inplace=True)\n","\n","# confirm no missing value remaining\n","assert all(df.isna().sum()) == 0"]},{"cell_type":"markdown","metadata":{"id":"nXmI8Y0s5tRD"},"source":["# Subsampling\n","\n","The original datasets are too large use in DIVA as they are. Therefore, I need to resample the datasets to a sample size that is more favourable for the resources at hand.\n","\n","Originally, I was to use a sample size of 10000, however, such a sample size took to long to impute. I subsampled to 5000, then 1000 and finally settled on 1500."]},{"cell_type":"markdown","metadata":{"id":"IBtpxyLg6vIi"},"source":["## Random sampling\n","\n","This method was used on data with continuous target variables as it is not likely to mess up the distribution alot.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QQ1E6ZGwJlZN"},"outputs":[],"source":["# resample the data by random sampling\n","samp1_df = df.sample(n=1500, replace=False, random_state=42, ignore_index=False)\n","\n","# export as a csv file\n","samp1_df.to_csv(path_or_buf=file_dir.removesuffix(\".csv\") + \"_resampled.csv\")"]},{"cell_type":"markdown","metadata":{"id":"0qvETQw67EUo"},"source":["## Stratified sampling\n","\n","This method is better than random sampling for data with categorical target variables as it maintains the original data distribution in the sample."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QA1vDQ0TJlZN","outputId":"8a3a58a9-1ac2-4933-efbf-d0b5f2894dcb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original ratio: 0.1478893974678123\n","0.148\n","0.14788477090827964\n"]}],"source":["# resample the data by stratified sampling (FOR CATEGORICAL TARGET VARIABLES)\n","sampler = StratifiedShuffleSplit(n_splits=1, random_state=42, train_size=1500/df.shape[0], )\n","\n","# specify target variable\n","target = \"repay_fail\"\n","\n","X = df.drop(target, axis=1)\n","df[target].replace({\"yes\": 1, \"no\":0}, inplace=True)\n","y = df[target]\n","\n","original_ratio = df[target].sum() / df.shape[0]\n","train, test = None, None\n","\n","for train_idx, test_idx in sampler.split(X=X, y=y):\n","    train = train_idx\n","    test = test_idx\n","\n","samp2_df = df.loc[train]\n","test_data = df.loc[test]\n","\n","# check if original ditribution is maintained\n","print(\"Original ratio:\", original_ratio)\n","print(samp2_df[target].sum() / samp2_df.shape[0])\n","print(test_data[target].sum() / test_data.shape[0])\n","\n","# export as a csv file\n","samp2_df.to_csv(path_or_buf=file_dir.removesuffix(\".csv\") + \"_resampled.csv\")"]},{"cell_type":"markdown","metadata":{"id":"EfixyC9x8jL_"},"source":["For small datasets that do not require subsampling, replacement of the original data is done inplace."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XXp7USatJlZO"},"outputs":[],"source":["# # Export cleaned data (Replacement)\n","# df.to_csv(file_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VysDneBeJlZO"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"pylearn","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
